{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7eee2e0-eb0f-4feb-b6d4-e2a32aa114a3",
   "metadata": {},
   "source": [
    "# Training Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8d195e-989c-404a-8a0a-1827291e7ac6",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c929b5ac-aae6-4a68-9c39-0de00d008ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "import torch.quantization as tq\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "949fc0d5-27dd-49ac-9e85-4f3ff3f8b339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94160390-1c1c-4438-8b89-bad3688163ad",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "- MNIST\n",
    "- train, validation and test-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "988180c0-a36c-43a5-8e9a-4837a1a3d7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 4200\n",
      "val size: 5000\n",
      "unused_size: 50800\n",
      "test size: 10000\n",
      "\n",
      "batch size: 64\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download MNIST\n",
    "full_train = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Split: 50k train / 10k validation\n",
    "train_size = 4_200\n",
    "val_size = 5_000\n",
    "unused_size = len(full_train) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, _ = random_split(\n",
    "    full_train, [train_size, val_size, unused_size]\n",
    ")\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def get_calib_loader(num_samples=1000, batch_size=batch_size):\n",
    "    indices = torch.randperm(len(train_dataset))[:num_samples]\n",
    "    calib_dataset = Subset(train_dataset, indices)\n",
    "    calib_loader = DataLoader(calib_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return calib_loader\n",
    "\n",
    "calib_loader = get_calib_loader(100)\n",
    "    \n",
    "\n",
    "print(\"train size:\", len(train_dataset))\n",
    "print(\"val size:\", len(val_dataset))\n",
    "if unused_size > 0:\n",
    "    print(\"unused_size:\", unused_size)\n",
    "print(\"test size:\", len(test_dataset))\n",
    "print(\"\\nbatch size:\", batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5097963-1487-417d-85c5-7a2a0eb857a6",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "- The NN-Architecture does not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d96321-774b-473b-a55a-14978bef0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FP32(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, bias=False)  # bias=False because bn1 has its own bias\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool  = nn.MaxPool2d(2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc1 = nn.Linear(5408, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bf5cd-a027-4d04-80d5-36b0f5a05a64",
   "metadata": {},
   "source": [
    "## Generic Training and Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc78fa5c-1cbb-4e18-88ff-ba1194449201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, epoch_num=1):\n",
    "    model.train()  # just sets the mode :)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    loader_with_tqdm = tqdm(loader, desc=f\"Training Epoch {epoch_num}\")\n",
    "    loader_with_tqdm.total = len(loader)\n",
    "\n",
    "    for x, y in loader_with_tqdm:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f7a154-c641-4c4b-ab26-79582715db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(net, loader):\n",
    "    net.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    total_time = 0\n",
    "    avg_time = 0\n",
    "\n",
    "    # loader_with_tqdm = tqdm(enumerate(loader), desc=f\"Evaluating Model\")\n",
    "    # loader_with_tqdm.total = len(loader)\n",
    "\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        start = time.perf_counter()\n",
    "        out = net(x)\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        total_time += end - start\n",
    "        avg_time += (end - start - avg_time) / (i + 1)\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    avg_time /= batch_size\n",
    "\n",
    "    avg_latency_ms = avg_time * 1000\n",
    "    throughput = 1 / avg_time\n",
    "    acc = correct / total\n",
    "    \n",
    "    return total_loss / len(loader), acc, total_time, avg_latency_ms, throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf24841-6862-42b0-a499-74f816840994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_size_mb(model) -> float:\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "        torch.save(model.state_dict(), tmp.name)\n",
    "        size_mb = os.path.getsize(tmp.name) / (1024 ** 2)\n",
    "    os.remove(tmp.name)\n",
    "    return size_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a2c30e-dd37-471f-a470-ef807e494ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, model_name=\"CNN\"):\n",
    "    test_loss, test_acc, total_time, latency, throughput = evaluate(net, test_loader)\n",
    "    test_size = model_size_mb(net)\n",
    "\n",
    "    print(f\"-- Evaluating {model_name} --\")\n",
    "    print(f\"{model_name} evaluation finished in {total_time:.4f}s\")\n",
    "    print(f\"{model_name} Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"{model_name} Model Size: {test_size:.4f}MB\")\n",
    "    print(f\"{model_name} Inference Latency: {latency:.4f}ms\")\n",
    "    print(f\"{model_name} Inference Throughput per second: {throughput:.0f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94e8bb03-17bb-49cb-9362-572c07b55c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_avg_latency(net, iterations=10):\n",
    "    total_avg_lat = 0\n",
    "    for _ in range(iterations):\n",
    "        _, _, _, avg, _ = evaluate(net, test_loader)\n",
    "        total_avg_lat += avg\n",
    "    avg_latency_ms = total_avg_lat / iterations\n",
    "    return avg_latency_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333c94d-4436-4c45-818a-8b5709aa159c",
   "metadata": {},
   "source": [
    "## Training\n",
    "- Train once or load if exists (if already trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19c64518-96ee-417d-9963-ef57ea12310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training FP32 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 49.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 1 in 1.3234822750091553 seconds with val_accuracy: 0.9156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 53.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 2 in 1.2287535667419434 seconds with val_accuracy: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 54.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 3 in 1.2178683280944824 seconds with val_accuracy: 0.9348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 54.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 4 in 1.2025132179260254 seconds with val_accuracy: 0.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 54.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 5 in 1.2070283889770508 seconds with val_accuracy: 0.9558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 55.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 6 in 1.1975290775299072 seconds with val_accuracy: 0.9590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 55.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 7 in 1.1900973320007324 seconds with val_accuracy: 0.9602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 53.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 8 in 1.2292978763580322 seconds with val_accuracy: 0.9596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|████████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 55.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 9 in 1.1916413307189941 seconds with val_accuracy: 0.9604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|███████████████████████████████████████████████████████████████| 66/66 [00:01<00:00, 55.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Epoch 10 in 1.1872296333312988 seconds with val_accuracy: 0.9604\n",
      "Training finished\n",
      "Total Time trained: 12.175441026687622\n",
      "Avg. Time per Epoch: 1.2175441026687621\n",
      "Model saved to: ./models/fp32.pth\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./models/fp32.pth\"\n",
    "\n",
    "model = FP32().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "val_accuracies = []\n",
    "epoch_train_times = []\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading trained FP32 model from disk...\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "\n",
    "else:\n",
    "    print(\"Training FP32 model...\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        start = time.time()\n",
    "        _ = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion, epoch_num=epoch+1\n",
    "        )\n",
    "        epoch_time = time.time() - start\n",
    "        \n",
    "        _, val_acc, _, _, _ = evaluate(\n",
    "            model, val_loader\n",
    "        )\n",
    "\n",
    "        epoch_train_times.append(epoch_time)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Trained Epoch {epoch+1} in {epoch_time} seconds with val_accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    print(\"Training finished\")\n",
    "\n",
    "    total_training_time = sum(epoch_train_times)\n",
    "    print(f\"Total Time trained: {total_training_time}\")\n",
    "    print(f\"Avg. Time per Epoch: {total_training_time / num_epochs}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(\"Model saved to:\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d2928-5988-4793-8315-b0d8cab0eb96",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "- generic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e06314d-76fa-42c2-a23d-770f41bbb07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluating PTQ Naive --\n",
      "PTQ Naive evaluation finished in 0.5508s\n",
      "PTQ Naive Test Accuracy: 0.9582\n",
      "PTQ Naive Model Size: 2.6512MB\n",
      "PTQ Naive Inference Latency: 0.0548ms\n",
      "PTQ Naive Inference Throughput per second: 18241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, model_name=\"PTQ Naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f4b0cf-a2fe-4480-a07c-ed128cede5bd",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b748b188-8cdd-46d3-a2f4-a61e53b8efd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "10048\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(test_loader) * batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9dfb2-e940-46b1-8f3b-f017474009b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PTQ (Naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eda24ab-66ac-4513-8b7f-a900d1971c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaivePTQ(FP32):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = torch.quantization.QuantStub()  # introduces observers\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = super().forward(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81d8f886-9931-48ae-b552-18d124d99c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaivePTQ(\n",
       "  (conv1): Conv2d(\n",
       "    1, 32, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(\n",
       "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (fc1): Linear(\n",
       "    in_features=5408, out_features=128, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu2): ReLU()\n",
       "  (fc2): Linear(\n",
       "    in_features=128, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_ptq_naive = NaivePTQ().to(device)\n",
    "net_ptq_naive.load_state_dict(model.state_dict())\n",
    "net_ptq_naive.eval()\n",
    "\n",
    "net_ptq_naive.qconfig = torch.ao.quantization.default_qconfig\n",
    "net_ptq_naive = torch.ao.quantization.prepare(net_ptq_naive)  # insert observers for callibration / MinMaxObservers\n",
    "net_ptq_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047d4c7-a4e3-4ea0-997d-e2cf7acca249",
   "metadata": {},
   "source": [
    "### Callibrate with evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8213539e-363f-45c7-84c1-3f5ce9d30f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0026195072568953037,\n",
       " 1.0,\n",
       " 0.008057600003667176,\n",
       " 0.06295000002864981,\n",
       " 15885.623503492929)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calibration\n",
    "evaluate(net_ptq_naive, calib_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f143951-a53d-484d-bf0f-0afd37975063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaivePTQ(\n",
       "  (conv1): Conv2d(\n",
       "    1, 32, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
       "    (activation_post_process): MinMaxObserver(min_val=-0.80129075050354, max_val=1.168089747428894)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(\n",
       "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-9.63398551940918, max_val=9.405465126037598)\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (fc1): Linear(\n",
       "    in_features=5408, out_features=128, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-27.501049041748047, max_val=31.70554542541504)\n",
       "  )\n",
       "  (relu2): ReLU()\n",
       "  (fc2): Linear(\n",
       "    in_features=128, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=-16.36876106262207, max_val=20.98222541809082)\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=0.0, max_val=1.0)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing all observed min and max values\n",
    "net_ptq_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a028107b-d3b3-4077-99af-df2322e46993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaivePTQ(\n",
       "  (conv1): QuantizedConv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.015506933443248272, zero_point=52, bias=False)\n",
       "  (bn1): QuantizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (fc1): QuantizedLinear(in_features=5408, out_features=128, scale=0.46619367599487305, zero_point=59, qscheme=torch.per_tensor_affine)\n",
       "  (relu2): ReLU()\n",
       "  (fc2): QuantizedLinear(in_features=128, out_features=10, scale=0.2941022515296936, zero_point=56, qscheme=torch.per_tensor_affine)\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual quantization:\n",
    "net_ptq_naive = torch.ao.quantization.convert(net_ptq_naive)\n",
    "net_ptq_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3870e7-949e-43a0-888d-4127232636e0",
   "metadata": {},
   "source": [
    "this results in assymatric quantization: Each layer has a scale and a zero_point to quantized the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855fc66-f312-41d5-ad42-f8b4726cb0de",
   "metadata": {},
   "source": [
    "### Compare weights with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c93810f-5d5a-46ab-ae6b-3fb1f2fe7242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of FT32 baseline:\n",
      "tensor([[[ 0.1728,  0.2110, -0.0973],\n",
      "         [-0.2779, -0.2402, -0.2528],\n",
      "         [ 0.1140,  0.1251,  0.2860]]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "\n",
      "Quantized Weights of naive_ptq:\n",
      "tensor([[[ 55,  67, -31],\n",
      "         [-88, -76, -81],\n",
      "         [ 36,  40,  91]]], dtype=torch.int8)\n",
      "\n",
      "\n",
      "Dequantized Weights of naive_ptq:\n",
      "tensor([[[ 0.1727,  0.2104, -0.0973],\n",
      "         [-0.2763, -0.2387, -0.2544],\n",
      "         [ 0.1130,  0.1256,  0.2858]]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weights of FT32 baseline:\")\n",
    "print(model.conv1.weight[0])\n",
    "print(\"\\n\")\n",
    "print(f\"Quantized Weights of naive_ptq:\")\n",
    "print(torch.int_repr(net_ptq_naive.conv1.weight()[0]))\n",
    "print(\"\\n\")\n",
    "print(f\"Dequantized Weights of naive_ptq:\")\n",
    "print(torch.dequantize(net_ptq_naive.conv1.weight()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0feb242-27bb-44a2-857a-519ac516352e",
   "metadata": {},
   "source": [
    "### Evaluate PTQNaive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31cffd83-d903-464a-89d6-a499493b04d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluating PTQ Naive --\n",
      "PTQ Naive evaluation finished in 0.2320s\n",
      "PTQ Naive Test Accuracy: 0.9582\n",
      "PTQ Naive Model Size: 0.6691MB\n",
      "PTQ Naive Inference Latency: 0.0231ms\n",
      "PTQ Naive Inference Throughput per second: 43305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(net_ptq_naive, model_name=\"PTQ Naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d550c4-4a4f-467d-956d-5a752e4d140f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PTQ + Bias Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e114b-c7fb-4d59-80a0-6bdbeb4ffb80",
   "metadata": {},
   "source": [
    "- Bias Correction operates layer-wise\n",
    "- After PTQ a layer computes:\n",
    "$$\n",
    "y_q=W_qx_q+b\n",
    "$$\n",
    "- The Idea for Bias Correction:\n",
    "$$\n",
    "\\mathbb{E}[W_qx_q]\\neq\\mathbb{E}[Wx]\n",
    "$$\n",
    "- fix in bias $b$ of NN:\n",
    "$$\n",
    "b'=b+\\mathbb{E}[Wx]-\\mathbb{E}[W_qx_q]\n",
    "$$\n",
    "- new output:\n",
    "$$\n",
    "y_q=W_qx_q+b'\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1efda2a-c0ec-4a19-a115-8016c4084553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_layer_outputs(net, loader, layers):\n",
    "    outputs = {name: [] for name in layers}\n",
    "\n",
    "    hooks = []\n",
    "\n",
    "    def make_hook(name):\n",
    "        def hook(module, inp, out):\n",
    "            outputs[name].append(out.detach().cpu())\n",
    "        return hook\n",
    "\n",
    "    for name, module in net.named_modules():\n",
    "        if name in layers:\n",
    "            hooks.append(module.register_forward_hook(make_hook(name)))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, _ in loader:\n",
    "            x = x.to(device)\n",
    "            net(x)\n",
    "\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return {k: torch.cat(v, dim=0) for k, v in outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fcdb4c3-71d0-4d69-965a-852a13701e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_correction_pre_convert(fp32_model, prepared_model, calib_loader):\n",
    "    layers = [\n",
    "        name for name, m in fp32_model.named_modules()\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)) and m.bias is not None\n",
    "    ]\n",
    "\n",
    "    fp32_outs = collect_layer_outputs(fp32_model, calib_loader, layers)\n",
    "    prep_outs = collect_layer_outputs(prepared_model, calib_loader, layers)\n",
    "\n",
    "    for name in layers:\n",
    "        fp32 = fp32_outs[name]\n",
    "        prep = prep_outs[name]\n",
    "\n",
    "        if fp32.dim() == 4:   # Conv\n",
    "            delta = (fp32 - prep).mean(dim=(0, 2, 3))\n",
    "        else:                 # Linear\n",
    "            delta = (fp32 - prep).mean(dim=0)\n",
    "\n",
    "        module = dict(prepared_model.named_modules())[name]\n",
    "        module.bias.data += delta.to(module.bias.device)\n",
    "\n",
    "    return prepared_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd71fa58-6db8-4fc7-946b-80c19a7b4093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaivePTQ(\n",
       "  (conv1): Conv2d(\n",
       "    1, 32, kernel_size=(3, 3), stride=(1, 1), bias=False\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(\n",
       "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (fc1): Linear(\n",
       "    in_features=5408, out_features=128, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu2): ReLU()\n",
       "  (fc2): Linear(\n",
       "    in_features=128, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_bias = NaivePTQ().to(device)\n",
    "net_bias.load_state_dict(model.state_dict())\n",
    "net_bias.eval()\n",
    "\n",
    "net_bias.qconfig = torch.ao.quantization.default_qconfig\n",
    "torch.ao.quantization.prepare(net_bias, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b051481f-125c-419c-9e8d-fa214a205d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FP32(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (fc1): Linear(in_features=5408, out_features=128, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp32_ref = FP32().to(device)\n",
    "fp32_ref.load_state_dict(model.state_dict())\n",
    "fp32_ref.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb8495f9-e51e-4d20-9bb7-193a8e888cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_bias = bias_correction_pre_convert(\n",
    "    fp32_ref,\n",
    "    net_bias,\n",
    "    calib_loader\n",
    ")\n",
    "\n",
    "net_bias = torch.ao.quantization.convert(net_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89164ad9-9142-44bd-8590-01f914dd853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluating PTQ with Bias Correction --\n",
      "PTQ with Bias Correction evaluation finished in 0.2212s\n",
      "PTQ with Bias Correction Test Accuracy: 0.9582\n",
      "PTQ with Bias Correction Model Size: 0.6691MB\n",
      "PTQ with Bias Correction Inference Latency: 0.0220ms\n",
      "PTQ with Bias Correction Inference Throughput per second: 45435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(net_bias, model_name=\"PTQ with Bias Correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96027df3-c1bc-491c-a671-93b0f68270f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PTQ + BN Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71b9501a-1be8-4471-b1a6-bbd25a7e53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PTQ_BN_Folding(FP32):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = super().forward(x)  # (Fusion will replace conv1+bn1+relu1 with a single ConvReLU module)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a6ccb74-0edf-48c7-9b81-fba9c5cb2f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PTQ_BN_Folding(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (fc1): Linear(in_features=5408, out_features=128, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weights from the trained BN model\n",
    "net_ptq_fold = PTQ_BN_Folding().to(device)\n",
    "net_ptq_fold.load_state_dict(model.state_dict())\n",
    "net_ptq_fold.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6a29bdc-d9fe-479d-9725-5cf61223c4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PTQ_BN_Folding(\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (bn1): Identity()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): Identity()\n",
       "  (fc1): Linear(in_features=5408, out_features=128, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fusing Conv2d + BatchNorm2d + ReLU\n",
    "torch.ao.quantization.fuse_modules(\n",
    "    net_ptq_fold, \n",
    "    [['conv1', 'bn1', 'relu1']], \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49035f38-bd9e-4eed-bc55-9d5e1772b1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PTQ_BN_Folding(\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (bn1): Identity()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): Identity()\n",
       "  (fc1): Linear(\n",
       "    in_features=5408, out_features=128, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (relu2): ReLU()\n",
       "  (fc2): Linear(\n",
       "    in_features=128, out_features=10, bias=True\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare (Insert Observers)\n",
    "net_ptq_fold.qconfig = torch.ao.quantization.default_qconfig\n",
    "torch.ao.quantization.prepare(net_ptq_fold, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9edba52f-f933-4a31-8ddc-a8d749ffa592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0016541487129870802,\n",
       " 1.0,\n",
       " 0.006810900056734681,\n",
       " 0.053210156693239696,\n",
       " 18793.404532993023)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calibrate\n",
    "evaluate(net_ptq_fold, calib_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62d99071-7117-403a-ba9e-ee1e8d42cf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PTQ_BN_Folding(\n",
       "  (conv1): QuantizedConvReLU2d(1, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.07639258354902267, zero_point=0)\n",
       "  (bn1): Identity()\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): Identity()\n",
       "  (fc1): QuantizedLinear(in_features=5408, out_features=128, scale=0.4036511182785034, zero_point=57, qscheme=torch.per_tensor_affine)\n",
       "  (relu2): ReLU()\n",
       "  (fc2): QuantizedLinear(in_features=128, out_features=10, scale=0.30629250407218933, zero_point=59, qscheme=torch.per_tensor_affine)\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual quantization\n",
    "torch.ao.quantization.convert(net_ptq_fold, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "841a1839-ad20-45f1-8c12-e85b8f158319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluating PTQ with BN Folding --\n",
      "PTQ with BN Folding evaluation finished in 0.1784s\n",
      "PTQ with BN Folding Test Accuracy: 0.9622\n",
      "PTQ with BN Folding Model Size: 0.6672MB\n",
      "PTQ with BN Folding Inference Latency: 0.0178ms\n",
      "PTQ with BN Folding Inference Throughput per second: 56313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test(net_ptq_fold, model_name=\"PTQ with BN Folding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b5703-84d3-42f0-b0ae-08e5e49aa5a8",
   "metadata": {},
   "source": [
    "# Mixed Precision PTQ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "827f83c2-ab35-47c8-a7f7-7f963b039541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_sensitivity(fp32_model, quantized_model, loader):\n",
    "    \"\"\"\n",
    "    Compares layer outputs of FP32 vs Quantized model to find the most sensitive layers.\n",
    "    \"\"\"\n",
    "    fp32_model.eval()\n",
    "    quantized_model.eval()\n",
    "    \n",
    "    # We only care about weighted layers\n",
    "    target_layers = [nn.Conv2d, nn.Linear]\n",
    "    \n",
    "    # Store outputs here\n",
    "    outputs_fp32 = {}\n",
    "    outputs_quant = {}\n",
    "    \n",
    "    # --- Hooks ---\n",
    "    def save_output(container, name):\n",
    "        def hook(module, inp, out):\n",
    "            # If output is quantized (quint8), dequantize it for comparison\n",
    "            if out.is_quantized:\n",
    "                out = out.dequantize()\n",
    "            container[name] = out.detach().cpu()\n",
    "        return hook\n",
    "\n",
    "    # Register hooks\n",
    "    handles = []\n",
    "    for name, mod in fp32_model.named_modules():\n",
    "        if isinstance(mod, tuple(target_layers)):\n",
    "            handles.append(mod.register_forward_hook(save_output(outputs_fp32, name)))\n",
    "            \n",
    "    for name, mod in quantized_model.named_modules():\n",
    "        if isinstance(mod, tuple(target_layers)):\n",
    "            handles.append(mod.register_forward_hook(save_output(outputs_quant, name)))\n",
    "\n",
    "    # --- Run Inference (1 Batch is usually enough) ---\n",
    "    x, _ = next(iter(loader))\n",
    "    x = x.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        fp32_model(x)\n",
    "        quantized_model(x)\n",
    "\n",
    "    # --- Cleanup Hooks ---\n",
    "    for h in handles:\n",
    "        h.remove()\n",
    "\n",
    "    # --- Calculate MSE Error ---\n",
    "    layer_scores = {}\n",
    "    for name in outputs_fp32.keys():\n",
    "        if name in outputs_quant:\n",
    "            # MSE: Mean Squared Error\n",
    "            diff = (outputs_fp32[name] - outputs_quant[name]).pow(2).mean()\n",
    "            layer_scores[name] = diff.item()\n",
    "\n",
    "    return layer_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "40d8a396-87c0-49e7-8137-c8df581f0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensitivity(sensitivity_dict):\n",
    "    layers = list(sensitivity_dict.keys())\n",
    "    errors = list(sensitivity_dict.values())\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(layers, errors, color='salmon')\n",
    "    plt.ylabel('MSE Loss (Sensitivity)')\n",
    "    plt.title('Layer-wise Quantization Sensitivity (Lower is Better)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "47731d03-c494-4194-b78b-6f7770e07aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Layer Sensitivity...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Sensitive Layers (High MSE = Bad):\n"
     ]
    }
   ],
   "source": [
    "# --- RUN ANALYSIS ---\n",
    "# Ensure you have your latest models ready:\n",
    "# 1. model_bn (The FP32 Baseline)\n",
    "# 2. net_ptq_fold (The Quantized Model)\n",
    "\n",
    "print(\"Analyzing Layer Sensitivity...\")\n",
    "sensitivity = get_layer_sensitivity(model, net_ptq_fold, calib_loader)\n",
    "plot_sensitivity(sensitivity)\n",
    "\n",
    "# Print sorted most sensitive layers\n",
    "sorted_layers = sorted(sensitivity.items(), key=lambda item: item[1], reverse=True)\n",
    "print(\"\\nMost Sensitive Layers (High MSE = Bad):\")\n",
    "for name, score in sorted_layers:\n",
    "    print(f\"{name}: {score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e6cf12-7f25-4ee0-944a-dd910050b863",
   "metadata": {},
   "source": [
    "# QAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b818c54-f5bc-43f7-8a81-926d266b6ba5",
   "metadata": {},
   "source": [
    "# Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "350afe73-ef3e-47ce-9152-65ade1f73b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluating FP32 Baseline --\n",
      "FP32 Baseline evaluation finished in 0.4786s\n",
      "FP32 Baseline Test Accuracy: 0.9627\n",
      "FP32 Baseline Model Size: 2.6512MB\n",
      "FP32 Baseline Inference Latency: 0.0476ms\n",
      "FP32 Baseline Inference Throughput per second: 20995\n",
      "\n",
      "-- Evaluating PTQ Naive --\n",
      "PTQ Naive evaluation finished in 0.2002s\n",
      "PTQ Naive Test Accuracy: 0.9582\n",
      "PTQ Naive Model Size: 0.6691MB\n",
      "PTQ Naive Inference Latency: 0.0199ms\n",
      "PTQ Naive Inference Throughput per second: 50191\n",
      "\n",
      "-- Evaluating PTQ with Bias Correction --\n",
      "PTQ with Bias Correction evaluation finished in 0.1944s\n",
      "PTQ with Bias Correction Test Accuracy: 0.9582\n",
      "PTQ with Bias Correction Model Size: 0.6691MB\n",
      "PTQ with Bias Correction Inference Latency: 0.0193ms\n",
      "PTQ with Bias Correction Inference Throughput per second: 51685\n",
      "\n",
      "-- Evaluating PTQ with BN Folding --\n",
      "PTQ with BN Folding evaluation finished in 0.1892s\n",
      "PTQ with BN Folding Test Accuracy: 0.9622\n",
      "PTQ with BN Folding Model Size: 0.6672MB\n",
      "PTQ with BN Folding Inference Latency: 0.0188ms\n",
      "PTQ with BN Folding Inference Throughput per second: 53097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, model_name=\"FP32 Baseline\")\n",
    "test(net_ptq_naive, model_name=\"PTQ Naive\")\n",
    "test(net_bias, model_name=\"PTQ with Bias Correction\")\n",
    "test(net_ptq_fold, model_name=\"PTQ with BN Folding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ded07fa3-df12-4aad-a913-3a4724ef191c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 latency: 0.0507ms\n",
      "PTQ Naive latency: 0.0204ms\n",
      "PTQ Bias Correction latency: 0.0222ms\n",
      "PTQ BN Folding latency: 0.0175ms\n"
     ]
    }
   ],
   "source": [
    "print(f\"FP32 latency: {calculating_avg_latency(model):.4f}ms\")\n",
    "print(f\"PTQ Naive latency: {calculating_avg_latency(net_ptq_naive):.4f}ms\")\n",
    "print(f\"PTQ Bias Correction latency: {calculating_avg_latency(net_bias):.4f}ms\")\n",
    "print(f\"PTQ BN Folding latency: {calculating_avg_latency(net_ptq_fold):.4f}ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
